{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44c4228f-cc9e-4500-a624-7bf46e59ab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9e92a7e-5ac2-47f8-a014-58cfd99ca5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb87df87-6a67-47fe-8f5e-523a5f59d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"stop being a dumbass dumbass , you are a moron of the highest level. Nobody can matchy your idiocy. A pen standing on its head is smarter than you on your best day. A language model is a model of the human brain's ability to produce natural language.[1][2] Language models are useful for a variety of tasks, including speech recognition,[3] machine translation,[4] natural language generation (generating more human-like text), optical character recognition, route optimization,[5] handwriting recognition,[6] grammar induction,[7] and information retrieval.[8][9] Large language models (LLMs), currently their most advanced form, are predominantly based on transformers trained on larger datasets (frequently using texts scraped from the public internet). They have superseded recurrent neural network-based models, which had previously superseded the purely statistical models, such as the word n-gram language model.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c5b7394-365c-4f3b-9377-34e91deaf862",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1d7f251-7cb9-44eb-a785-4c1c15392ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0435c926-c22b-4c38-8a5f-3809d371e8d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stop',\n",
       " 'being',\n",
       " 'a',\n",
       " 'dumb',\n",
       " '##ass',\n",
       " 'dumb',\n",
       " '##ass',\n",
       " ',',\n",
       " 'you',\n",
       " 'are',\n",
       " 'a',\n",
       " 'mor',\n",
       " '##on',\n",
       " 'of',\n",
       " 'the',\n",
       " 'highest',\n",
       " 'level',\n",
       " '.',\n",
       " 'nobody',\n",
       " 'can',\n",
       " 'match',\n",
       " '##y',\n",
       " 'your',\n",
       " 'id',\n",
       " '##io',\n",
       " '##cy',\n",
       " '.',\n",
       " 'a',\n",
       " 'pen',\n",
       " 'standing',\n",
       " 'on',\n",
       " 'its',\n",
       " 'head',\n",
       " 'is',\n",
       " 'smarter',\n",
       " 'than',\n",
       " 'you',\n",
       " 'on',\n",
       " 'your',\n",
       " 'best',\n",
       " 'day',\n",
       " '.',\n",
       " 'a',\n",
       " 'language',\n",
       " 'model',\n",
       " 'is',\n",
       " 'a',\n",
       " 'model',\n",
       " 'of',\n",
       " 'the',\n",
       " 'human',\n",
       " 'brain',\n",
       " \"'\",\n",
       " 's',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'produce',\n",
       " 'natural',\n",
       " 'language',\n",
       " '.',\n",
       " '[',\n",
       " '1',\n",
       " ']',\n",
       " '[',\n",
       " '2',\n",
       " ']',\n",
       " 'language',\n",
       " 'models',\n",
       " 'are',\n",
       " 'useful',\n",
       " 'for',\n",
       " 'a',\n",
       " 'variety',\n",
       " 'of',\n",
       " 'tasks',\n",
       " ',',\n",
       " 'including',\n",
       " 'speech',\n",
       " 'recognition',\n",
       " ',',\n",
       " '[',\n",
       " '3',\n",
       " ']',\n",
       " 'machine',\n",
       " 'translation',\n",
       " ',',\n",
       " '[',\n",
       " '4',\n",
       " ']',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'generation',\n",
       " '(',\n",
       " 'generating',\n",
       " 'more',\n",
       " 'human',\n",
       " '-',\n",
       " 'like',\n",
       " 'text',\n",
       " ')',\n",
       " ',',\n",
       " 'optical',\n",
       " 'character',\n",
       " 'recognition',\n",
       " ',',\n",
       " 'route',\n",
       " 'optimization',\n",
       " ',',\n",
       " '[',\n",
       " '5',\n",
       " ']',\n",
       " 'handwriting',\n",
       " 'recognition',\n",
       " ',',\n",
       " '[',\n",
       " '6',\n",
       " ']',\n",
       " 'grammar',\n",
       " 'induction',\n",
       " ',',\n",
       " '[',\n",
       " '7',\n",
       " ']',\n",
       " 'and',\n",
       " 'information',\n",
       " 'retrieval',\n",
       " '.',\n",
       " '[',\n",
       " '8',\n",
       " ']',\n",
       " '[',\n",
       " '9',\n",
       " ']',\n",
       " 'large',\n",
       " 'language',\n",
       " 'models',\n",
       " '(',\n",
       " 'll',\n",
       " '##ms',\n",
       " ')',\n",
       " ',',\n",
       " 'currently',\n",
       " 'their',\n",
       " 'most',\n",
       " 'advanced',\n",
       " 'form',\n",
       " ',',\n",
       " 'are',\n",
       " 'predominantly',\n",
       " 'based',\n",
       " 'on',\n",
       " 'transformers',\n",
       " 'trained',\n",
       " 'on',\n",
       " 'larger',\n",
       " 'data',\n",
       " '##set',\n",
       " '##s',\n",
       " '(',\n",
       " 'frequently',\n",
       " 'using',\n",
       " 'texts',\n",
       " 'scraped',\n",
       " 'from',\n",
       " 'the',\n",
       " 'public',\n",
       " 'internet',\n",
       " ')',\n",
       " '.',\n",
       " 'they',\n",
       " 'have',\n",
       " 'superseded',\n",
       " 'rec',\n",
       " '##urrent',\n",
       " 'neural',\n",
       " 'network',\n",
       " '-',\n",
       " 'based',\n",
       " 'models',\n",
       " ',',\n",
       " 'which',\n",
       " 'had',\n",
       " 'previously',\n",
       " 'superseded',\n",
       " 'the',\n",
       " 'purely',\n",
       " 'statistical',\n",
       " 'models',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'the',\n",
       " 'word',\n",
       " 'n',\n",
       " '-',\n",
       " 'gram',\n",
       " 'language',\n",
       " 'model',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67db0261-5b55-4734-991b-89f3d07b0840",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_tokens=tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3482ed53-302f-4756-a309-8e7d0305cf1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vatsal.singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsal.singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsal.singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsal.singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsal.singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsal.singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsal.singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsal.singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsal.singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsal.singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsal.singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsal.singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsal.singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsal.singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsal.singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsal.singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsal.singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsal.singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsal.singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vatsal.singh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\google\\protobuf\\runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"stop being a dumbass dumbass, you are a moron of the highest level. nobody can matchy your idiocy. a pen standing on its head is smarter than you on your best day. a language model is a model of the human brain ' s ability to produce natural language. [ 1 ] [ 2 ] language models are useful for a variety of tasks, including speech recognition, [ 3 ] machine translation, [ 4 ] natural language generation ( generating more human - like text ), optical character recognition, route optimization, [ 5 ] handwriting recognition, [ 6 ] grammar induction, [ 7 ] and information retrieval. [ 8 ] [ 9 ] large language models ( llms ), currently their most advanced form, are predominantly based on transformers trained on larger datasets ( frequently using texts scraped from the public internet ). they have superseded recurrent neural network - based models, which had previously superseded the purely statistical models, such as the word n - gram language model.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inp_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08c7074d-93d4-4621-94df-08a030f5061d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inp_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b378cae4-9121-41c0-9931-6a2cdb665f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "887b79bb-8302-428f-991e-365faaebaf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=[]\n",
    "y_val=[]\n",
    "for i in range(len(inp_tokens)-features):\n",
    "    vec=inp_tokens[i:i+features]\n",
    "    train_data.append(vec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "938ba14b-d242-464e-a16d-a601a5f55281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'##ass'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_data[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0610dd3-4683-47d8-8dc6-12d70a531a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ca4a138-e55f-4e7e-8f14-4abba2389c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stop being a dumb'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_data[0][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b437a16a-3908-4331-aae6-47afa8ec04b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=np.array(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e96f9400-8e39-4c37-831e-f81e59d0cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val=torch.tensor(train_data[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ceafa54-6b7e-44b7-a013-cdaf4bca71b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y=torch.tensor(train_data[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29388727-392b-4e02-9b1d-0ef65560e8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b451c20e-279e-44e5-9105-2d26d34d92a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2644,  2108,  1037, 12873, 12054],\n",
       "       [ 2108,  1037, 12873, 12054, 12873],\n",
       "       [ 1037, 12873, 12054, 12873, 12054],\n",
       "       [12873, 12054, 12873, 12054,  1010],\n",
       "       [12054, 12873, 12054,  1010,  2017],\n",
       "       [12873, 12054,  1010,  2017,  2024],\n",
       "       [12054,  1010,  2017,  2024,  1037],\n",
       "       [ 1010,  2017,  2024,  1037, 22822],\n",
       "       [ 2017,  2024,  1037, 22822,  2239],\n",
       "       [ 2024,  1037, 22822,  2239,  1997],\n",
       "       [ 1037, 22822,  2239,  1997,  1996],\n",
       "       [22822,  2239,  1997,  1996,  3284],\n",
       "       [ 2239,  1997,  1996,  3284,  2504],\n",
       "       [ 1997,  1996,  3284,  2504,  1012],\n",
       "       [ 1996,  3284,  2504,  1012,  6343],\n",
       "       [ 3284,  2504,  1012,  6343,  2064],\n",
       "       [ 2504,  1012,  6343,  2064,  2674],\n",
       "       [ 1012,  6343,  2064,  2674,  2100],\n",
       "       [ 6343,  2064,  2674,  2100,  2115],\n",
       "       [ 2064,  2674,  2100,  2115,  8909],\n",
       "       [ 2674,  2100,  2115,  8909,  3695],\n",
       "       [ 2100,  2115,  8909,  3695,  5666],\n",
       "       [ 2115,  8909,  3695,  5666,  1012],\n",
       "       [ 8909,  3695,  5666,  1012,  1037],\n",
       "       [ 3695,  5666,  1012,  1037,  7279],\n",
       "       [ 5666,  1012,  1037,  7279,  3061],\n",
       "       [ 1012,  1037,  7279,  3061,  2006],\n",
       "       [ 1037,  7279,  3061,  2006,  2049],\n",
       "       [ 7279,  3061,  2006,  2049,  2132],\n",
       "       [ 3061,  2006,  2049,  2132,  2003],\n",
       "       [ 2006,  2049,  2132,  2003, 25670],\n",
       "       [ 2049,  2132,  2003, 25670,  2084],\n",
       "       [ 2132,  2003, 25670,  2084,  2017],\n",
       "       [ 2003, 25670,  2084,  2017,  2006],\n",
       "       [25670,  2084,  2017,  2006,  2115],\n",
       "       [ 2084,  2017,  2006,  2115,  2190],\n",
       "       [ 2017,  2006,  2115,  2190,  2154],\n",
       "       [ 2006,  2115,  2190,  2154,  1012],\n",
       "       [ 2115,  2190,  2154,  1012,  1037],\n",
       "       [ 2190,  2154,  1012,  1037,  2653],\n",
       "       [ 2154,  1012,  1037,  2653,  2944],\n",
       "       [ 1012,  1037,  2653,  2944,  2003],\n",
       "       [ 1037,  2653,  2944,  2003,  1037],\n",
       "       [ 2653,  2944,  2003,  1037,  2944],\n",
       "       [ 2944,  2003,  1037,  2944,  1997],\n",
       "       [ 2003,  1037,  2944,  1997,  1996],\n",
       "       [ 1037,  2944,  1997,  1996,  2529],\n",
       "       [ 2944,  1997,  1996,  2529,  4167],\n",
       "       [ 1997,  1996,  2529,  4167,  1005],\n",
       "       [ 1996,  2529,  4167,  1005,  1055],\n",
       "       [ 2529,  4167,  1005,  1055,  3754],\n",
       "       [ 4167,  1005,  1055,  3754,  2000],\n",
       "       [ 1005,  1055,  3754,  2000,  3965],\n",
       "       [ 1055,  3754,  2000,  3965,  3019],\n",
       "       [ 3754,  2000,  3965,  3019,  2653],\n",
       "       [ 2000,  3965,  3019,  2653,  1012],\n",
       "       [ 3965,  3019,  2653,  1012,  1031],\n",
       "       [ 3019,  2653,  1012,  1031,  1015],\n",
       "       [ 2653,  1012,  1031,  1015,  1033],\n",
       "       [ 1012,  1031,  1015,  1033,  1031],\n",
       "       [ 1031,  1015,  1033,  1031,  1016],\n",
       "       [ 1015,  1033,  1031,  1016,  1033],\n",
       "       [ 1033,  1031,  1016,  1033,  2653],\n",
       "       [ 1031,  1016,  1033,  2653,  4275],\n",
       "       [ 1016,  1033,  2653,  4275,  2024],\n",
       "       [ 1033,  2653,  4275,  2024,  6179],\n",
       "       [ 2653,  4275,  2024,  6179,  2005],\n",
       "       [ 4275,  2024,  6179,  2005,  1037],\n",
       "       [ 2024,  6179,  2005,  1037,  3528],\n",
       "       [ 6179,  2005,  1037,  3528,  1997],\n",
       "       [ 2005,  1037,  3528,  1997,  8518],\n",
       "       [ 1037,  3528,  1997,  8518,  1010],\n",
       "       [ 3528,  1997,  8518,  1010,  2164],\n",
       "       [ 1997,  8518,  1010,  2164,  4613],\n",
       "       [ 8518,  1010,  2164,  4613,  5038],\n",
       "       [ 1010,  2164,  4613,  5038,  1010],\n",
       "       [ 2164,  4613,  5038,  1010,  1031],\n",
       "       [ 4613,  5038,  1010,  1031,  1017],\n",
       "       [ 5038,  1010,  1031,  1017,  1033],\n",
       "       [ 1010,  1031,  1017,  1033,  3698],\n",
       "       [ 1031,  1017,  1033,  3698,  5449],\n",
       "       [ 1017,  1033,  3698,  5449,  1010],\n",
       "       [ 1033,  3698,  5449,  1010,  1031],\n",
       "       [ 3698,  5449,  1010,  1031,  1018],\n",
       "       [ 5449,  1010,  1031,  1018,  1033],\n",
       "       [ 1010,  1031,  1018,  1033,  3019],\n",
       "       [ 1031,  1018,  1033,  3019,  2653],\n",
       "       [ 1018,  1033,  3019,  2653,  4245],\n",
       "       [ 1033,  3019,  2653,  4245,  1006],\n",
       "       [ 3019,  2653,  4245,  1006, 11717],\n",
       "       [ 2653,  4245,  1006, 11717,  2062],\n",
       "       [ 4245,  1006, 11717,  2062,  2529],\n",
       "       [ 1006, 11717,  2062,  2529,  1011],\n",
       "       [11717,  2062,  2529,  1011,  2066],\n",
       "       [ 2062,  2529,  1011,  2066,  3793],\n",
       "       [ 2529,  1011,  2066,  3793,  1007],\n",
       "       [ 1011,  2066,  3793,  1007,  1010],\n",
       "       [ 2066,  3793,  1007,  1010,  9380],\n",
       "       [ 3793,  1007,  1010,  9380,  2839],\n",
       "       [ 1007,  1010,  9380,  2839,  5038],\n",
       "       [ 1010,  9380,  2839,  5038,  1010],\n",
       "       [ 9380,  2839,  5038,  1010,  2799],\n",
       "       [ 2839,  5038,  1010,  2799, 20600],\n",
       "       [ 5038,  1010,  2799, 20600,  1010],\n",
       "       [ 1010,  2799, 20600,  1010,  1031],\n",
       "       [ 2799, 20600,  1010,  1031,  1019],\n",
       "       [20600,  1010,  1031,  1019,  1033],\n",
       "       [ 1010,  1031,  1019,  1033, 24149],\n",
       "       [ 1031,  1019,  1033, 24149,  5038],\n",
       "       [ 1019,  1033, 24149,  5038,  1010],\n",
       "       [ 1033, 24149,  5038,  1010,  1031],\n",
       "       [24149,  5038,  1010,  1031,  1020],\n",
       "       [ 5038,  1010,  1031,  1020,  1033],\n",
       "       [ 1010,  1031,  1020,  1033,  8035],\n",
       "       [ 1031,  1020,  1033,  8035, 15946],\n",
       "       [ 1020,  1033,  8035, 15946,  1010],\n",
       "       [ 1033,  8035, 15946,  1010,  1031],\n",
       "       [ 8035, 15946,  1010,  1031,  1021],\n",
       "       [15946,  1010,  1031,  1021,  1033],\n",
       "       [ 1010,  1031,  1021,  1033,  1998],\n",
       "       [ 1031,  1021,  1033,  1998,  2592],\n",
       "       [ 1021,  1033,  1998,  2592, 26384],\n",
       "       [ 1033,  1998,  2592, 26384,  1012],\n",
       "       [ 1998,  2592, 26384,  1012,  1031],\n",
       "       [ 2592, 26384,  1012,  1031,  1022],\n",
       "       [26384,  1012,  1031,  1022,  1033],\n",
       "       [ 1012,  1031,  1022,  1033,  1031],\n",
       "       [ 1031,  1022,  1033,  1031,  1023],\n",
       "       [ 1022,  1033,  1031,  1023,  1033],\n",
       "       [ 1033,  1031,  1023,  1033,  2312],\n",
       "       [ 1031,  1023,  1033,  2312,  2653],\n",
       "       [ 1023,  1033,  2312,  2653,  4275],\n",
       "       [ 1033,  2312,  2653,  4275,  1006],\n",
       "       [ 2312,  2653,  4275,  1006,  2222],\n",
       "       [ 2653,  4275,  1006,  2222,  5244],\n",
       "       [ 4275,  1006,  2222,  5244,  1007],\n",
       "       [ 1006,  2222,  5244,  1007,  1010],\n",
       "       [ 2222,  5244,  1007,  1010,  2747],\n",
       "       [ 5244,  1007,  1010,  2747,  2037],\n",
       "       [ 1007,  1010,  2747,  2037,  2087],\n",
       "       [ 1010,  2747,  2037,  2087,  3935],\n",
       "       [ 2747,  2037,  2087,  3935,  2433],\n",
       "       [ 2037,  2087,  3935,  2433,  1010],\n",
       "       [ 2087,  3935,  2433,  1010,  2024],\n",
       "       [ 3935,  2433,  1010,  2024,  9197],\n",
       "       [ 2433,  1010,  2024,  9197,  2241],\n",
       "       [ 1010,  2024,  9197,  2241,  2006],\n",
       "       [ 2024,  9197,  2241,  2006, 19081],\n",
       "       [ 9197,  2241,  2006, 19081,  4738],\n",
       "       [ 2241,  2006, 19081,  4738,  2006],\n",
       "       [ 2006, 19081,  4738,  2006,  3469],\n",
       "       [19081,  4738,  2006,  3469,  2951],\n",
       "       [ 4738,  2006,  3469,  2951, 13462],\n",
       "       [ 2006,  3469,  2951, 13462,  2015],\n",
       "       [ 3469,  2951, 13462,  2015,  1006],\n",
       "       [ 2951, 13462,  2015,  1006,  4703],\n",
       "       [13462,  2015,  1006,  4703,  2478],\n",
       "       [ 2015,  1006,  4703,  2478,  6981],\n",
       "       [ 1006,  4703,  2478,  6981, 20378],\n",
       "       [ 4703,  2478,  6981, 20378,  2013],\n",
       "       [ 2478,  6981, 20378,  2013,  1996],\n",
       "       [ 6981, 20378,  2013,  1996,  2270],\n",
       "       [20378,  2013,  1996,  2270,  4274],\n",
       "       [ 2013,  1996,  2270,  4274,  1007],\n",
       "       [ 1996,  2270,  4274,  1007,  1012],\n",
       "       [ 2270,  4274,  1007,  1012,  2027],\n",
       "       [ 4274,  1007,  1012,  2027,  2031],\n",
       "       [ 1007,  1012,  2027,  2031, 19886],\n",
       "       [ 1012,  2027,  2031, 19886, 28667],\n",
       "       [ 2027,  2031, 19886, 28667, 29264],\n",
       "       [ 2031, 19886, 28667, 29264, 15756],\n",
       "       [19886, 28667, 29264, 15756,  2897],\n",
       "       [28667, 29264, 15756,  2897,  1011],\n",
       "       [29264, 15756,  2897,  1011,  2241],\n",
       "       [15756,  2897,  1011,  2241,  4275],\n",
       "       [ 2897,  1011,  2241,  4275,  1010],\n",
       "       [ 1011,  2241,  4275,  1010,  2029],\n",
       "       [ 2241,  4275,  1010,  2029,  2018],\n",
       "       [ 4275,  1010,  2029,  2018,  3130],\n",
       "       [ 1010,  2029,  2018,  3130, 19886],\n",
       "       [ 2029,  2018,  3130, 19886,  1996],\n",
       "       [ 2018,  3130, 19886,  1996, 11850],\n",
       "       [ 3130, 19886,  1996, 11850,  7778],\n",
       "       [19886,  1996, 11850,  7778,  4275],\n",
       "       [ 1996, 11850,  7778,  4275,  1010],\n",
       "       [11850,  7778,  4275,  1010,  2107],\n",
       "       [ 7778,  4275,  1010,  2107,  2004],\n",
       "       [ 4275,  1010,  2107,  2004,  1996],\n",
       "       [ 1010,  2107,  2004,  1996,  2773],\n",
       "       [ 2107,  2004,  1996,  2773,  1050],\n",
       "       [ 2004,  1996,  2773,  1050,  1011],\n",
       "       [ 1996,  2773,  1050,  1011, 13250],\n",
       "       [ 2773,  1050,  1011, 13250,  2653],\n",
       "       [ 1050,  1011, 13250,  2653,  2944]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1f7ccc7-f39e-4dff-865d-25d23acd8004",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2644,  2108,  1037, 12873],\n",
       "        [ 2108,  1037, 12873, 12054],\n",
       "        [ 1037, 12873, 12054, 12873],\n",
       "        [12873, 12054, 12873, 12054],\n",
       "        [12054, 12873, 12054,  1010],\n",
       "        [12873, 12054,  1010,  2017],\n",
       "        [12054,  1010,  2017,  2024],\n",
       "        [ 1010,  2017,  2024,  1037],\n",
       "        [ 2017,  2024,  1037, 22822],\n",
       "        [ 2024,  1037, 22822,  2239],\n",
       "        [ 1037, 22822,  2239,  1997],\n",
       "        [22822,  2239,  1997,  1996],\n",
       "        [ 2239,  1997,  1996,  3284],\n",
       "        [ 1997,  1996,  3284,  2504],\n",
       "        [ 1996,  3284,  2504,  1012],\n",
       "        [ 3284,  2504,  1012,  6343],\n",
       "        [ 2504,  1012,  6343,  2064],\n",
       "        [ 1012,  6343,  2064,  2674],\n",
       "        [ 6343,  2064,  2674,  2100],\n",
       "        [ 2064,  2674,  2100,  2115],\n",
       "        [ 2674,  2100,  2115,  8909],\n",
       "        [ 2100,  2115,  8909,  3695],\n",
       "        [ 2115,  8909,  3695,  5666],\n",
       "        [ 8909,  3695,  5666,  1012],\n",
       "        [ 3695,  5666,  1012,  1037],\n",
       "        [ 5666,  1012,  1037,  7279],\n",
       "        [ 1012,  1037,  7279,  3061],\n",
       "        [ 1037,  7279,  3061,  2006],\n",
       "        [ 7279,  3061,  2006,  2049],\n",
       "        [ 3061,  2006,  2049,  2132],\n",
       "        [ 2006,  2049,  2132,  2003],\n",
       "        [ 2049,  2132,  2003, 25670],\n",
       "        [ 2132,  2003, 25670,  2084],\n",
       "        [ 2003, 25670,  2084,  2017],\n",
       "        [25670,  2084,  2017,  2006],\n",
       "        [ 2084,  2017,  2006,  2115],\n",
       "        [ 2017,  2006,  2115,  2190],\n",
       "        [ 2006,  2115,  2190,  2154],\n",
       "        [ 2115,  2190,  2154,  1012],\n",
       "        [ 2190,  2154,  1012,  1037],\n",
       "        [ 2154,  1012,  1037,  2653],\n",
       "        [ 1012,  1037,  2653,  2944],\n",
       "        [ 1037,  2653,  2944,  2003],\n",
       "        [ 2653,  2944,  2003,  1037],\n",
       "        [ 2944,  2003,  1037,  2944],\n",
       "        [ 2003,  1037,  2944,  1997],\n",
       "        [ 1037,  2944,  1997,  1996],\n",
       "        [ 2944,  1997,  1996,  2529],\n",
       "        [ 1997,  1996,  2529,  4167],\n",
       "        [ 1996,  2529,  4167,  1005],\n",
       "        [ 2529,  4167,  1005,  1055],\n",
       "        [ 4167,  1005,  1055,  3754],\n",
       "        [ 1005,  1055,  3754,  2000],\n",
       "        [ 1055,  3754,  2000,  3965],\n",
       "        [ 3754,  2000,  3965,  3019],\n",
       "        [ 2000,  3965,  3019,  2653],\n",
       "        [ 3965,  3019,  2653,  1012],\n",
       "        [ 3019,  2653,  1012,  1031],\n",
       "        [ 2653,  1012,  1031,  1015],\n",
       "        [ 1012,  1031,  1015,  1033],\n",
       "        [ 1031,  1015,  1033,  1031],\n",
       "        [ 1015,  1033,  1031,  1016],\n",
       "        [ 1033,  1031,  1016,  1033],\n",
       "        [ 1031,  1016,  1033,  2653],\n",
       "        [ 1016,  1033,  2653,  4275],\n",
       "        [ 1033,  2653,  4275,  2024],\n",
       "        [ 2653,  4275,  2024,  6179],\n",
       "        [ 4275,  2024,  6179,  2005],\n",
       "        [ 2024,  6179,  2005,  1037],\n",
       "        [ 6179,  2005,  1037,  3528],\n",
       "        [ 2005,  1037,  3528,  1997],\n",
       "        [ 1037,  3528,  1997,  8518],\n",
       "        [ 3528,  1997,  8518,  1010],\n",
       "        [ 1997,  8518,  1010,  2164],\n",
       "        [ 8518,  1010,  2164,  4613],\n",
       "        [ 1010,  2164,  4613,  5038],\n",
       "        [ 2164,  4613,  5038,  1010],\n",
       "        [ 4613,  5038,  1010,  1031],\n",
       "        [ 5038,  1010,  1031,  1017],\n",
       "        [ 1010,  1031,  1017,  1033],\n",
       "        [ 1031,  1017,  1033,  3698],\n",
       "        [ 1017,  1033,  3698,  5449],\n",
       "        [ 1033,  3698,  5449,  1010],\n",
       "        [ 3698,  5449,  1010,  1031],\n",
       "        [ 5449,  1010,  1031,  1018],\n",
       "        [ 1010,  1031,  1018,  1033],\n",
       "        [ 1031,  1018,  1033,  3019],\n",
       "        [ 1018,  1033,  3019,  2653],\n",
       "        [ 1033,  3019,  2653,  4245],\n",
       "        [ 3019,  2653,  4245,  1006],\n",
       "        [ 2653,  4245,  1006, 11717],\n",
       "        [ 4245,  1006, 11717,  2062],\n",
       "        [ 1006, 11717,  2062,  2529],\n",
       "        [11717,  2062,  2529,  1011],\n",
       "        [ 2062,  2529,  1011,  2066],\n",
       "        [ 2529,  1011,  2066,  3793],\n",
       "        [ 1011,  2066,  3793,  1007],\n",
       "        [ 2066,  3793,  1007,  1010],\n",
       "        [ 3793,  1007,  1010,  9380],\n",
       "        [ 1007,  1010,  9380,  2839],\n",
       "        [ 1010,  9380,  2839,  5038],\n",
       "        [ 9380,  2839,  5038,  1010],\n",
       "        [ 2839,  5038,  1010,  2799],\n",
       "        [ 5038,  1010,  2799, 20600],\n",
       "        [ 1010,  2799, 20600,  1010],\n",
       "        [ 2799, 20600,  1010,  1031],\n",
       "        [20600,  1010,  1031,  1019],\n",
       "        [ 1010,  1031,  1019,  1033],\n",
       "        [ 1031,  1019,  1033, 24149],\n",
       "        [ 1019,  1033, 24149,  5038],\n",
       "        [ 1033, 24149,  5038,  1010],\n",
       "        [24149,  5038,  1010,  1031],\n",
       "        [ 5038,  1010,  1031,  1020],\n",
       "        [ 1010,  1031,  1020,  1033],\n",
       "        [ 1031,  1020,  1033,  8035],\n",
       "        [ 1020,  1033,  8035, 15946],\n",
       "        [ 1033,  8035, 15946,  1010],\n",
       "        [ 8035, 15946,  1010,  1031],\n",
       "        [15946,  1010,  1031,  1021],\n",
       "        [ 1010,  1031,  1021,  1033],\n",
       "        [ 1031,  1021,  1033,  1998],\n",
       "        [ 1021,  1033,  1998,  2592],\n",
       "        [ 1033,  1998,  2592, 26384],\n",
       "        [ 1998,  2592, 26384,  1012],\n",
       "        [ 2592, 26384,  1012,  1031],\n",
       "        [26384,  1012,  1031,  1022],\n",
       "        [ 1012,  1031,  1022,  1033],\n",
       "        [ 1031,  1022,  1033,  1031],\n",
       "        [ 1022,  1033,  1031,  1023],\n",
       "        [ 1033,  1031,  1023,  1033],\n",
       "        [ 1031,  1023,  1033,  2312],\n",
       "        [ 1023,  1033,  2312,  2653],\n",
       "        [ 1033,  2312,  2653,  4275],\n",
       "        [ 2312,  2653,  4275,  1006],\n",
       "        [ 2653,  4275,  1006,  2222],\n",
       "        [ 4275,  1006,  2222,  5244],\n",
       "        [ 1006,  2222,  5244,  1007],\n",
       "        [ 2222,  5244,  1007,  1010],\n",
       "        [ 5244,  1007,  1010,  2747],\n",
       "        [ 1007,  1010,  2747,  2037],\n",
       "        [ 1010,  2747,  2037,  2087],\n",
       "        [ 2747,  2037,  2087,  3935],\n",
       "        [ 2037,  2087,  3935,  2433],\n",
       "        [ 2087,  3935,  2433,  1010],\n",
       "        [ 3935,  2433,  1010,  2024],\n",
       "        [ 2433,  1010,  2024,  9197],\n",
       "        [ 1010,  2024,  9197,  2241],\n",
       "        [ 2024,  9197,  2241,  2006],\n",
       "        [ 9197,  2241,  2006, 19081],\n",
       "        [ 2241,  2006, 19081,  4738],\n",
       "        [ 2006, 19081,  4738,  2006],\n",
       "        [19081,  4738,  2006,  3469],\n",
       "        [ 4738,  2006,  3469,  2951],\n",
       "        [ 2006,  3469,  2951, 13462],\n",
       "        [ 3469,  2951, 13462,  2015],\n",
       "        [ 2951, 13462,  2015,  1006],\n",
       "        [13462,  2015,  1006,  4703],\n",
       "        [ 2015,  1006,  4703,  2478],\n",
       "        [ 1006,  4703,  2478,  6981],\n",
       "        [ 4703,  2478,  6981, 20378],\n",
       "        [ 2478,  6981, 20378,  2013],\n",
       "        [ 6981, 20378,  2013,  1996],\n",
       "        [20378,  2013,  1996,  2270],\n",
       "        [ 2013,  1996,  2270,  4274],\n",
       "        [ 1996,  2270,  4274,  1007],\n",
       "        [ 2270,  4274,  1007,  1012],\n",
       "        [ 4274,  1007,  1012,  2027],\n",
       "        [ 1007,  1012,  2027,  2031],\n",
       "        [ 1012,  2027,  2031, 19886],\n",
       "        [ 2027,  2031, 19886, 28667],\n",
       "        [ 2031, 19886, 28667, 29264],\n",
       "        [19886, 28667, 29264, 15756],\n",
       "        [28667, 29264, 15756,  2897],\n",
       "        [29264, 15756,  2897,  1011],\n",
       "        [15756,  2897,  1011,  2241],\n",
       "        [ 2897,  1011,  2241,  4275],\n",
       "        [ 1011,  2241,  4275,  1010],\n",
       "        [ 2241,  4275,  1010,  2029],\n",
       "        [ 4275,  1010,  2029,  2018],\n",
       "        [ 1010,  2029,  2018,  3130],\n",
       "        [ 2029,  2018,  3130, 19886],\n",
       "        [ 2018,  3130, 19886,  1996],\n",
       "        [ 3130, 19886,  1996, 11850],\n",
       "        [19886,  1996, 11850,  7778],\n",
       "        [ 1996, 11850,  7778,  4275],\n",
       "        [11850,  7778,  4275,  1010],\n",
       "        [ 7778,  4275,  1010,  2107],\n",
       "        [ 4275,  1010,  2107,  2004],\n",
       "        [ 1010,  2107,  2004,  1996],\n",
       "        [ 2107,  2004,  1996,  2773],\n",
       "        [ 2004,  1996,  2773,  1050],\n",
       "        [ 1996,  2773,  1050,  1011],\n",
       "        [ 2773,  1050,  1011, 13250],\n",
       "        [ 1050,  1011, 13250,  2653]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "526aed1c-cb55-4ab3-b66e-6974b87aef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "vsize=tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3558299-04b2-49cf-adf3-b140a397099e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac2326a7-5f1f-45d9-bf73-f4feb7559011",
   "metadata": {},
   "outputs": [],
   "source": [
    "class neur(nn.Module):\n",
    "    def __init__(self,feats,endvocab):\n",
    "        super().__init__()\n",
    "        self.fc1=nn.Linear(feats-1,1000)\n",
    "        self.fc2=nn.Linear(1000,2000)\n",
    "        self.fc3=nn.Linear(2000,endvocab)\n",
    "        self.sigm=nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        x=self.fc1(x)\n",
    "        x=self.sigm(x)\n",
    "        x=self.fc2(x)\n",
    "        x=self.sigm(x)\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c77935ae-df2b-4cb8-be22-e25b3dcca4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "skynet=neur(features,vsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5153789-b1bf-4bbd-b330-2594ed03005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48ba1454-14c2-4132-a685-f64901aaf18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.Adam(skynet.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1cce7e18-3316-4c1f-8f9a-61bb27b18e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46bbcaca-53e3-4ce1-acca-537dfe15952a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vatsal.singh\\AppData\\Local\\Temp\\ipykernel_21404\\2047908359.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val=torch.tensor(val,dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "val=torch.tensor(val,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2db01ef8-e734-422f-a719-0055fde02d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.4297, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.0978, grad_fn=<NllLossBackward0>)\n",
      "tensor(5.8437, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.5875, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.3275, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2801, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2866, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.2642, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1847, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.1188, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0872, grad_fn=<NllLossBackward0>)\n",
      "tensor(4.0459, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9768, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.9006, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.8329, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.7685, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6978, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.6209, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.5461, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4756, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.4079, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.3427, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2786, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.2156, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1561, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.1000, grad_fn=<NllLossBackward0>)\n",
      "tensor(3.0445, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9883, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.9330, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8797, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.8271, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7748, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.7230, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6721, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.6217, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5715, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.5218, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4728, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.4243, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3759, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3280, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2806, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2338, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1876, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1417, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0963, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0516, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.0076, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9642, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.9215, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8792, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.8378, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7969, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7569, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.7173, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6783, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6401, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.6026, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5656, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.5291, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4933, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4585, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4243, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3905, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3575, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3252, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2934, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2623, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2320, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2021, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1729, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1446, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1165, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0890, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0622, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0363, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9863, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9623, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9388, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9162, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8940, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8725, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8517, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8313, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8115, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7923, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7737, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7557, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7382, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7045, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6886, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6729, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6579, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6433, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6291, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6153, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5889, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5764, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5643, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5525, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5410, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5299, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4988, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4886, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4789, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4697, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4608, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4521, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4437, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4353, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4273, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4043, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3970, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3903, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3834, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3767, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3703, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3640, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3580, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3520, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3463, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3406, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3350, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3298, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3246, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3196, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3145, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3096, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3048, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2958, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2914, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2874, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2834, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2795, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2753, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2718, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2676, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2642, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2603, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2570, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2535, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2500, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2470, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2435, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2406, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2374, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2344, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2316, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2286, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2260, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2180, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2154, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2130, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2105, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2083, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2056, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2036, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2019, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1995, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1968, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1951, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1937, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1913, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1890, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1873, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1856, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1840, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1816, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1794, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1779, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1761, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1743, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1725, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1711, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1698, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1686, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1674, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1659, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1640, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1624, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1605, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1591, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1583, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1568, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1557, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1544, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1529, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1511, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1499, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1487, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    out=skynet(val)\n",
    "    loss=criterion(out,val_y)\n",
    "    print(loss)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35fa7721-a941-41c2-bd12-520356e8857d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inp_text=\"stop being a dumb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7869167-9a3c-4002-9ba5-658a613721f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_text_tokens=tokenizer.tokenize(inp_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da61a8c6-47d8-44ba-81bb-972cce8ae9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inptokens=tokenizer.convert_tokens_to_ids(inp_text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ef4a43b-82e6-4414-87f7-83b6c77e1fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2644, 2108, 1037, 12873]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inptokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f07b839-0ce7-4442-8eaf-fbe0c8f7ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(inptokens)<features:\n",
    "    for i in range(features-len(inptokens)-1):\n",
    "        inptokens.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06424476-1992-4b98-9ab5-86ab2f7d77e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2644, 2108, 1037, 12873]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inptokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4945b43-00b4-4777-b18d-0e5ccc2ddb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "inptokens=inptokens[-features+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7bc4e444-f7cf-46df-ae95-1d3f5962052f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2644, 2108, 1037, 12873]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inptokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8bcb7bcc-2d88-41a9-bd8e-ae47f0622604",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c65e7e7-7c57-4e9c-8a15-473826b6021e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "]\n",
      "language\n",
      "models\n",
      "are\n",
      "useful\n",
      "for\n",
      "a\n",
      "variety\n",
      "of\n",
      "tasks\n",
      ",\n",
      "including\n",
      "speech\n",
      "recognition\n",
      ",\n",
      "[\n",
      "3\n",
      "]\n",
      "[\n",
      "2\n",
      "]\n",
      "language\n",
      "models\n",
      "are\n",
      "useful\n",
      "for\n",
      "a\n",
      "variety\n",
      "of\n",
      "tasks\n",
      ",\n",
      "including\n",
      "speech\n",
      "recognition\n",
      ",\n",
      "[\n",
      "3\n",
      "]\n",
      "[\n",
      "2\n",
      "]\n",
      "language\n",
      "models\n",
      "are\n",
      "useful\n",
      "for\n",
      "a\n",
      "variety\n",
      "of\n",
      "tasks\n",
      ",\n",
      "including\n",
      "speech\n",
      "recognition\n",
      ",\n",
      "[\n",
      "3\n",
      "]\n",
      "[\n",
      "2\n",
      "]\n",
      "language\n",
      "models\n",
      "are\n",
      "useful\n",
      "for\n",
      "a\n",
      "variety\n",
      "of\n",
      "tasks\n",
      ",\n",
      "including\n",
      "speech\n",
      "recognition\n",
      ",\n",
      "[\n",
      "3\n",
      "]\n",
      "[\n",
      "2\n",
      "]\n",
      "language\n",
      "models\n",
      "are\n",
      "useful\n",
      "for\n",
      "a\n",
      "variety\n",
      "of\n",
      "tasks\n",
      ",\n",
      "including\n",
      "speech\n",
      "recognition\n",
      ",\n",
      "[\n",
      "3\n",
      "]\n",
      "[\n",
      "2\n",
      "]\n",
      "language\n",
      "models\n",
      "are\n",
      "useful\n",
      "for\n",
      "a\n",
      "variety\n",
      "of\n",
      "tasks\n",
      ",\n",
      "including\n",
      "speech\n",
      "recognition\n",
      ",\n",
      "[\n",
      "3\n",
      "]\n",
      "[\n",
      "2\n",
      "]\n",
      "language\n",
      "models\n",
      "are\n",
      "useful\n",
      "for\n",
      "a\n",
      "variety\n",
      "of\n",
      "tasks\n",
      ",\n",
      "including\n",
      "speech\n",
      "recognition\n",
      ",\n",
      "[\n",
      "3\n",
      "]\n",
      "[\n",
      "2\n",
      "]\n",
      "language\n",
      "models\n",
      "are\n",
      "useful\n",
      "for\n",
      "a\n",
      "variety\n",
      "of\n",
      "tasks\n",
      ",\n",
      "including\n",
      "speech\n",
      "recognition\n",
      ",\n",
      "[\n",
      "3\n",
      "]\n",
      "[\n",
      "2\n",
      "]\n",
      "language\n",
      "models\n",
      "are\n",
      "useful\n",
      "for\n",
      "a\n",
      "variety\n",
      "of\n",
      "tasks\n",
      ",\n",
      "including\n",
      "speech\n",
      "recognition\n",
      ",\n",
      "[\n",
      "3\n",
      "]\n",
      "[\n",
      "2\n",
      "]\n",
      "language\n",
      "models\n",
      "are\n",
      "useful\n",
      "for\n",
      "a\n",
      "variety\n",
      "of\n",
      "tasks\n",
      ",\n",
      "including\n",
      "speech\n",
      "recognition\n",
      ",\n",
      "[\n",
      "3\n",
      "]\n",
      "[\n"
     ]
    }
   ],
   "source": [
    "for i in range(gen):\n",
    "    inptokens2=inptokens[-features+1:]\n",
    "    temptens=torch.tensor(inptokens2,dtype=torch.float32)\n",
    "    outw=skynet(temptens)\n",
    "    _, predicted = torch.max(outw, 0)\n",
    "    print(tokenizer.decode(predicted))\n",
    "    inptokens.append(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b542e495-d987-45a5-bb42-c10991ebf240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"stop being a dumbass dumbass, you are a moron of the highest level. nobody can matchy your idiocy. a pen standing on its head is smarter than you on your best day. a language model is a model of the human brain ' s ability to produce natural language. [ 1 ] [ 2 ] language models are useful for a variety of tasks, including speech recognition, [ 3 ] [ 2 ] language models are useful for a variety of tasks, including speech recognition, [ 3 ] [ 2 ] language models are useful for a variety of tasks, including speech recognition, [ 3 ] [ 2 ] language models are useful for a variety of tasks, including speech recognition, [ 3 ] [ 2 ] language models are useful for a variety of tasks, including speech recognition, [ 3 ] [ 2 ] language models are useful for a variety of tasks, including speech recognition, [ 3 ] [ 2 ] language models are useful for a variety of tasks, including speech recognition, [ 3 ] [ 2 ] language models are useful for a variety of tasks, including speech recognition, [ 3 ] [ 2 ] language models are useful for a variety of tasks, including speech recognition, [ 3 ] [ 2 ] language models are useful for a variety of tasks, including speech recognition, [ 3 ] [ 2 ] language models are useful for a variety of tasks, including speech recognition, [ 3 ] [ 2 ] language models are useful for a variety of tasks, including speech recognition, [ 3 ] [\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inptokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c06d1ae-98e6-4cad-9a3e-c7006e086dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
